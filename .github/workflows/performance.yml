name: Performance Monitoring

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests weekly
    - cron: '0 2 * * 0'

jobs:
  lighthouse:
    name: Lighthouse Audit
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci

    - name: Build frontend
      working-directory: ./frontend
      run: npm run build:prod
      env:
        REACT_APP_API_URL: http://localhost:5000/api
        GENERATE_SOURCEMAP: false

    - name: Run Lighthouse CI
      working-directory: ./frontend
      run: |
        npm install -g @lhci/cli@0.12.x
        lhci autorun
      env:
        LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

    - name: Upload Lighthouse results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: lighthouse-results
        path: |
          frontend/.lighthouseci
          frontend/lighthouse-results.json

  bundle-analysis:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci

    - name: Build and analyze bundle
      working-directory: ./frontend
      run: |
        npm run build:prod
        npx webpack-bundle-analyzer build/static/js/*.js --report --mode static --report-filename bundle-report.html
      env:
        REACT_APP_API_URL: https://api.example.com/api
        GENERATE_SOURCEMAP: false

    - name: Upload bundle analysis
      uses: actions/upload-artifact@v3
      with:
        name: bundle-analysis
        path: frontend/bundle-report.html

    - name: Check bundle size
      working-directory: ./frontend
      run: |
        BUNDLE_SIZE=$(du -sb build/static/js/*.js | awk '{sum += $1} END {print sum}')
        echo "Bundle size: $BUNDLE_SIZE bytes"
        
        # Fail if bundle is too large (2MB threshold)
        if [ $BUNDLE_SIZE -gt 2097152 ]; then
          echo "Bundle size exceeds 2MB limit"
          exit 1
        fi

  backend-performance:
    name: Backend Performance Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: contractguard_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: backend/package-lock.json

    - name: Install dependencies
      working-directory: ./backend
      run: npm ci

    - name: Build backend
      working-directory: ./backend
      run: npm run build

    - name: Setup test environment
      working-directory: ./backend
      run: |
        cp .env.example .env
        sed -i 's/your-super-secret-jwt-key-here-make-it-long-and-random/test-jwt-secret-key/' .env
        sed -i 's/your-openai-api-key-here/sk-test-key/' .env
        sed -i 's/postgresql:\/\/username:password@localhost:5432\/contractguard/postgresql:\/\/test_user:test_password@localhost:5432\/contractguard_test/' .env

    - name: Run database migrations
      working-directory: ./backend
      run: npm run migrate

    - name: Start backend server
      working-directory: ./backend
      run: |
        npm start &
        echo $! > server.pid
        sleep 10

    - name: Install k6
      run: |
        sudo gpg -k
        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6

    - name: Run performance tests
      run: |
        cat << 'EOF' > load-test.js
        import http from 'k6/http';
        import { check, group } from 'k6';
        
        export let options = {
          stages: [
            { duration: '30s', target: 10 },
            { duration: '1m', target: 20 },
            { duration: '30s', target: 0 },
          ],
          thresholds: {
            http_req_duration: ['p(95)<500'],
            http_req_failed: ['rate<0.1'],
          },
        };
        
        export default function () {
          group('API Health Check', () => {
            let response = http.get('http://localhost:5000/health');
            check(response, {
              'health check status is 200': (r) => r.status === 200,
              'health check response time < 100ms': (r) => r.timings.duration < 100,
            });
          });
        }
        EOF
        
        k6 run --out json=performance-results.json load-test.js

    - name: Stop backend server
      working-directory: ./backend
      run: |
        if [ -f server.pid ]; then
          kill $(cat server.pid) || true
          rm server.pid
        fi

    - name: Upload performance results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: backend-performance-results
        path: performance-results.json

  performance-regression:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    needs: [lighthouse, bundle-analysis]
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: lighthouse-results
        path: ./lighthouse-results

    - name: Performance regression check
      run: |
        echo "Performance regression check would compare results here"
        echo "This would typically compare against baseline metrics"
        echo "and fail the build if performance degrades significantly"

  performance-report:
    name: Performance Report
    runs-on: ubuntu-latest
    needs: [lighthouse, bundle-analysis, backend-performance]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3

    - name: Generate performance report
      run: |
        echo "# Performance Report" > performance-report.md
        echo "Date: $(date)" >> performance-report.md
        echo "" >> performance-report.md
        
        echo "## Lighthouse Results" >> performance-report.md
        if [ -d "lighthouse-results" ]; then
          echo "✅ Lighthouse audit completed" >> performance-report.md
        else
          echo "❌ Lighthouse audit failed" >> performance-report.md
        fi
        
        echo "## Bundle Analysis" >> performance-report.md
        if [ -f "bundle-analysis/bundle-report.html" ]; then
          echo "✅ Bundle analysis completed" >> performance-report.md
        else
          echo "❌ Bundle analysis failed" >> performance-report.md
        fi
        
        echo "## Backend Performance" >> performance-report.md
        if [ -f "backend-performance-results/performance-results.json" ]; then
          echo "✅ Backend performance tests completed" >> performance-report.md
        else
          echo "❌ Backend performance tests failed" >> performance-report.md
        fi

    - name: Comment PR with performance report
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('performance-report.md')) {
            const report = fs.readFileSync('performance-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
          }